{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning and Random Forests\n",
    "\n",
    "## Voting Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC(probability = True) # 保证 soft voting 可以使用\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# iris = datasets.load_iris()\n",
    "# X = iris[\"data\"][:,(2,3)]\n",
    "# y = (iris[\"target\"]==2)\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864\n",
      "0.896\n",
      "0.888\n",
      "0.904\n"
     ]
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 为了得到一系列不同的分类器，一种做法是使用不同的分类算法，另一种是使用不同的训练子集\n",
    "- 抽取子集中，有放回抽样称为 bagging ，无放回称为 pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging and Pasting in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92000000000000004"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1\n",
    "    )\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-Bag Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=100, n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1, oob_score=True\n",
    "    )\n",
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92266666666666663"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.32901554,  0.67098446],\n",
       "       [ 0.36314363,  0.63685637],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.00540541,  0.99459459],\n",
       "       [ 0.00795756,  0.99204244],\n",
       "       [ 0.11253197,  0.88746803],\n",
       "       [ 0.3655914 ,  0.6344086 ],\n",
       "       [ 0.0835443 ,  0.9164557 ],\n",
       "       [ 0.95115681,  0.04884319],\n",
       "       [ 0.80901857,  0.19098143],\n",
       "       [ 0.56657963,  0.43342037],\n",
       "       [ 0.05583756,  0.94416244],\n",
       "       [ 0.75      ,  0.25      ],\n",
       "       [ 0.83739837,  0.16260163],\n",
       "       [ 0.92287234,  0.07712766],\n",
       "       [ 0.1       ,  0.9       ],\n",
       "       [ 0.0483871 ,  0.9516129 ],\n",
       "       [ 0.91232877,  0.08767123],\n",
       "       [ 0.65364583,  0.34635417],\n",
       "       [ 0.95348837,  0.04651163],\n",
       "       [ 0.06015038,  0.93984962],\n",
       "       [ 0.23469388,  0.76530612],\n",
       "       [ 0.91002571,  0.08997429],\n",
       "       [ 0.98691099,  0.01308901],\n",
       "       [ 0.9507772 ,  0.0492228 ],\n",
       "       [ 0.00255102,  0.99744898],\n",
       "       [ 0.96883117,  0.03116883],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.02872063,  0.97127937],\n",
       "       [ 0.76      ,  0.24      ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.01058201,  0.98941799],\n",
       "       [ 0.06299213,  0.93700787],\n",
       "       [ 0.09536082,  0.90463918],\n",
       "       [ 0.98214286,  0.01785714],\n",
       "       [ 0.02156334,  0.97843666],\n",
       "       [ 0.56216216,  0.43783784],\n",
       "       [ 0.01897019,  0.98102981],\n",
       "       [ 0.99493671,  0.00506329],\n",
       "       [ 0.09585492,  0.90414508],\n",
       "       [ 0.36074271,  0.63925729],\n",
       "       [ 0.99748744,  0.00251256],\n",
       "       [ 0.98888889,  0.01111111],\n",
       "       [ 0.00995025,  0.99004975],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.06382979,  0.93617021],\n",
       "       [ 0.98      ,  0.02      ],\n",
       "       [ 0.06020942,  0.93979058],\n",
       "       [ 0.95431472,  0.04568528],\n",
       "       [ 0.82368421,  0.17631579],\n",
       "       [ 0.96418733,  0.03581267],\n",
       "       [ 0.80512821,  0.19487179],\n",
       "       [ 0.01546392,  0.98453608],\n",
       "       [ 0.13079019,  0.86920981],\n",
       "       [ 0.81606218,  0.18393782],\n",
       "       [ 0.01902174,  0.98097826],\n",
       "       [ 0.01344086,  0.98655914],\n",
       "       [ 0.06497175,  0.93502825],\n",
       "       [ 0.82901554,  0.17098446],\n",
       "       [ 0.64659686,  0.35340314],\n",
       "       [ 0.75989446,  0.24010554],\n",
       "       [ 0.98974359,  0.01025641],\n",
       "       [ 0.01842105,  0.98157895],\n",
       "       [ 0.78947368,  0.21052632],\n",
       "       [ 0.98143236,  0.01856764],\n",
       "       [ 0.9921875 ,  0.0078125 ],\n",
       "       [ 0.58126722,  0.41873278],\n",
       "       [ 0.99186992,  0.00813008],\n",
       "       [ 0.38520408,  0.61479592],\n",
       "       [ 0.31466667,  0.68533333],\n",
       "       [ 0.40954774,  0.59045226],\n",
       "       [ 0.64705882,  0.35294118],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.35516373,  0.64483627],\n",
       "       [ 0.89473684,  0.10526316],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.01558442,  0.98441558],\n",
       "       [ 0.96842105,  0.03157895],\n",
       "       [ 0.00555556,  0.99444444],\n",
       "       [ 0.2455243 ,  0.7544757 ],\n",
       "       [ 0.13114754,  0.86885246],\n",
       "       [ 0.45219638,  0.54780362],\n",
       "       [ 0.9867374 ,  0.0132626 ],\n",
       "       [ 0.05102041,  0.94897959],\n",
       "       [ 0.60574413,  0.39425587],\n",
       "       [ 0.05670103,  0.94329897],\n",
       "       [ 0.03367876,  0.96632124],\n",
       "       [ 0.0025641 ,  0.9974359 ],\n",
       "       [ 0.36898396,  0.63101604],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.00793651,  0.99206349],\n",
       "       [ 0.05194805,  0.94805195],\n",
       "       [ 0.01052632,  0.98947368],\n",
       "       [ 0.81679389,  0.18320611],\n",
       "       [ 0.66486486,  0.33513514],\n",
       "       [ 0.07552083,  0.92447917],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.30503979,  0.69496021],\n",
       "       [ 0.68463612,  0.31536388],\n",
       "       [ 0.00542005,  0.99457995],\n",
       "       [ 0.0928382 ,  0.9071618 ],\n",
       "       [ 0.44358974,  0.55641026],\n",
       "       [ 0.97333333,  0.02666667],\n",
       "       [ 0.05714286,  0.94285714],\n",
       "       [ 0.96741855,  0.03258145],\n",
       "       [ 0.44414894,  0.55585106],\n",
       "       [ 0.29896907,  0.70103093],\n",
       "       [ 0.99740933,  0.00259067],\n",
       "       [ 0.19023136,  0.80976864],\n",
       "       [ 0.85714286,  0.14285714],\n",
       "       [ 0.26614987,  0.73385013],\n",
       "       [ 0.79434447,  0.20565553],\n",
       "       [ 0.99224806,  0.00775194],\n",
       "       [ 0.98677249,  0.01322751],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.40159574,  0.59840426],\n",
       "       [ 0.99210526,  0.00789474],\n",
       "       [ 0.07853403,  0.92146597],\n",
       "       [ 0.99212598,  0.00787402],\n",
       "       [ 0.96134021,  0.03865979],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.94805195,  0.05194805],\n",
       "       [ 0.96952909,  0.03047091],\n",
       "       [ 0.03674541,  0.96325459],\n",
       "       [ 0.9379845 ,  0.0620155 ],\n",
       "       [ 0.95287958,  0.04712042],\n",
       "       [ 0.02835052,  0.97164948],\n",
       "       [ 0.20207254,  0.79792746],\n",
       "       [ 0.88295165,  0.11704835],\n",
       "       [ 0.33947368,  0.66052632],\n",
       "       [ 0.88859416,  0.11140584],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.03580563,  0.96419437],\n",
       "       [ 0.85675676,  0.14324324],\n",
       "       [ 0.78125   ,  0.21875   ],\n",
       "       [ 0.56578947,  0.43421053],\n",
       "       [ 0.86578947,  0.13421053],\n",
       "       [ 0.94764398,  0.05235602],\n",
       "       [ 0.13589744,  0.86410256],\n",
       "       [ 0.83804627,  0.16195373],\n",
       "       [ 0.03957784,  0.96042216],\n",
       "       [ 0.00547945,  0.99452055],\n",
       "       [ 0.1056701 ,  0.8943299 ],\n",
       "       [ 0.73629243,  0.26370757],\n",
       "       [ 0.97402597,  0.02597403],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.03826531,  0.96173469],\n",
       "       [ 0.00775194,  0.99224806],\n",
       "       [ 0.07671233,  0.92328767],\n",
       "       [ 0.03636364,  0.96363636],\n",
       "       [ 0.9973545 ,  0.0026455 ],\n",
       "       [ 0.98717949,  0.01282051],\n",
       "       [ 0.90078329,  0.09921671],\n",
       "       [ 0.99497487,  0.00502513],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.87958115,  0.12041885],\n",
       "       [ 0.00740741,  0.99259259],\n",
       "       [ 0.69712794,  0.30287206],\n",
       "       [ 0.35714286,  0.64285714],\n",
       "       [ 0.06544503,  0.93455497],\n",
       "       [ 0.01081081,  0.98918919],\n",
       "       [ 0.35459184,  0.64540816],\n",
       "       [ 0.99742268,  0.00257732],\n",
       "       [ 0.96569921,  0.03430079],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.98921833,  0.01078167],\n",
       "       [ 0.07329843,  0.92670157],\n",
       "       [ 0.00277008,  0.99722992],\n",
       "       [ 0.94892473,  0.05107527],\n",
       "       [ 0.0078534 ,  0.9921466 ],\n",
       "       [ 0.0025641 ,  0.9974359 ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.05249344,  0.94750656],\n",
       "       [ 0.86233766,  0.13766234],\n",
       "       [ 0.92950392,  0.07049608],\n",
       "       [ 0.05851064,  0.94148936],\n",
       "       [ 0.95336788,  0.04663212],\n",
       "       [ 0.89405685,  0.10594315],\n",
       "       [ 0.96658098,  0.03341902],\n",
       "       [ 0.0136612 ,  0.9863388 ],\n",
       "       [ 0.01876676,  0.98123324],\n",
       "       [ 0.99459459,  0.00540541],\n",
       "       [ 0.24744898,  0.75255102],\n",
       "       [ 0.99738903,  0.00261097],\n",
       "       [ 0.08967391,  0.91032609],\n",
       "       [ 0.02144772,  0.97855228],\n",
       "       [ 0.98984772,  0.01015228],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.16931217,  0.83068783],\n",
       "       [ 0.86920981,  0.13079019],\n",
       "       [ 0.93085106,  0.06914894],\n",
       "       [ 0.62992126,  0.37007874],\n",
       "       [ 0.68717949,  0.31282051],\n",
       "       [ 0.03045685,  0.96954315],\n",
       "       [ 0.24473684,  0.75526316],\n",
       "       [ 0.9921671 ,  0.0078329 ],\n",
       "       [ 0.92553191,  0.07446809],\n",
       "       [ 0.92010309,  0.07989691],\n",
       "       [ 0.99197861,  0.00802139],\n",
       "       [ 0.0610687 ,  0.9389313 ],\n",
       "       [ 0.00777202,  0.99222798],\n",
       "       [ 0.10026385,  0.89973615],\n",
       "       [ 0.47880299,  0.52119701],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.02083333,  0.97916667],\n",
       "       [ 0.96825397,  0.03174603],\n",
       "       [ 0.08549223,  0.91450777],\n",
       "       [ 0.096     ,  0.904     ],\n",
       "       [ 0.88431877,  0.11568123],\n",
       "       [ 0.05177112,  0.94822888],\n",
       "       [ 0.33766234,  0.66233766],\n",
       "       [ 0.00524934,  0.99475066],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.02356021,  0.97643979],\n",
       "       [ 0.01025641,  0.98974359],\n",
       "       [ 0.94358974,  0.05641026],\n",
       "       [ 0.90575916,  0.09424084],\n",
       "       [ 0.95419847,  0.04580153],\n",
       "       [ 0.02083333,  0.97916667],\n",
       "       [ 0.09973046,  0.90026954],\n",
       "       [ 0.93157895,  0.06842105],\n",
       "       [ 0.15733333,  0.84266667],\n",
       "       [ 0.0026178 ,  0.9973822 ],\n",
       "       [ 0.30104712,  0.69895288],\n",
       "       [ 0.98941799,  0.01058201],\n",
       "       [ 0.80506329,  0.19493671],\n",
       "       [ 0.09350649,  0.90649351],\n",
       "       [ 0.71717172,  0.28282828],\n",
       "       [ 0.93899204,  0.06100796],\n",
       "       [ 0.20754717,  0.79245283],\n",
       "       [ 0.18575064,  0.81424936],\n",
       "       [ 0.99232737,  0.00767263],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.02056555,  0.97943445],\n",
       "       [ 0.01412429,  0.98587571],\n",
       "       [ 0.38005391,  0.61994609],\n",
       "       [ 0.88337469,  0.11662531],\n",
       "       [ 0.0525    ,  0.9475    ],\n",
       "       [ 0.9921875 ,  0.0078125 ],\n",
       "       [ 0.86458333,  0.13541667],\n",
       "       [ 0.00263158,  0.99736842],\n",
       "       [ 0.78306878,  0.21693122],\n",
       "       [ 0.98488665,  0.01511335],\n",
       "       [ 0.01305483,  0.98694517],\n",
       "       [ 0.99742931,  0.00257069],\n",
       "       [ 0.06596306,  0.93403694],\n",
       "       [ 0.0127551 ,  0.9872449 ],\n",
       "       [ 0.09375   ,  0.90625   ],\n",
       "       [ 0.2159383 ,  0.7840617 ],\n",
       "       [ 0.82561308,  0.17438692],\n",
       "       [ 0.07571802,  0.92428198],\n",
       "       [ 0.99222798,  0.00777202],\n",
       "       [ 0.64646465,  0.35353535],\n",
       "       [ 0.10824742,  0.89175258],\n",
       "       [ 0.66321244,  0.33678756],\n",
       "       [ 0.87405542,  0.12594458],\n",
       "       [ 0.0104712 ,  0.9895288 ],\n",
       "       [ 0.99737533,  0.00262467],\n",
       "       [ 0.0156658 ,  0.9843342 ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.7382199 ,  0.2617801 ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.99206349,  0.00793651],\n",
       "       [ 0.09923664,  0.90076336],\n",
       "       [ 0.72335025,  0.27664975],\n",
       "       [ 0.12664908,  0.87335092],\n",
       "       [ 0.99742268,  0.00257732],\n",
       "       [ 0.8787062 ,  0.1212938 ],\n",
       "       [ 0.00527704,  0.99472296],\n",
       "       [ 0.08549223,  0.91450777],\n",
       "       [ 0.17312661,  0.82687339],\n",
       "       [ 0.0989011 ,  0.9010989 ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.97900262,  0.02099738],\n",
       "       [ 0.83797468,  0.16202532],\n",
       "       [ 0.17098446,  0.82901554],\n",
       "       [ 0.89361702,  0.10638298],\n",
       "       [ 0.06914894,  0.93085106],\n",
       "       [ 0.59067358,  0.40932642],\n",
       "       [ 0.14248021,  0.85751979],\n",
       "       [ 0.95767196,  0.04232804],\n",
       "       [ 0.91688312,  0.08311688],\n",
       "       [ 0.00767263,  0.99232737],\n",
       "       [ 0.91581633,  0.08418367],\n",
       "       [ 0.92838196,  0.07161804],\n",
       "       [ 0.00262467,  0.99737533],\n",
       "       [ 0.043257  ,  0.956743  ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.01530612,  0.98469388],\n",
       "       [ 0.99191375,  0.00808625],\n",
       "       [ 0.06878307,  0.93121693],\n",
       "       [ 0.88624339,  0.11375661],\n",
       "       [ 0.9973545 ,  0.0026455 ],\n",
       "       [ 0.01069519,  0.98930481],\n",
       "       [ 0.05789474,  0.94210526],\n",
       "       [ 0.70512821,  0.29487179],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.65217391,  0.34782609],\n",
       "       [ 0.85602094,  0.14397906],\n",
       "       [ 0.99741602,  0.00258398],\n",
       "       [ 0.70408163,  0.29591837],\n",
       "       [ 0.45103093,  0.54896907],\n",
       "       [ 0.03191489,  0.96808511],\n",
       "       [ 0.83727034,  0.16272966],\n",
       "       [ 0.01033592,  0.98966408],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.77486911,  0.22513089],\n",
       "       [ 0.99742931,  0.00257069],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.83827493,  0.16172507],\n",
       "       [ 0.27480916,  0.72519084],\n",
       "       [ 0.15938303,  0.84061697],\n",
       "       [ 0.24512535,  0.75487465],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.73924051,  0.26075949],\n",
       "       [ 0.90769231,  0.09230769],\n",
       "       [ 0.02949062,  0.97050938],\n",
       "       [ 0.99479167,  0.00520833],\n",
       "       [ 0.96240602,  0.03759398],\n",
       "       [ 0.99485861,  0.00514139],\n",
       "       [ 0.00526316,  0.99473684],\n",
       "       [ 0.04712042,  0.95287958],\n",
       "       [ 0.95478723,  0.04521277],\n",
       "       [ 0.93573265,  0.06426735],\n",
       "       [ 0.99748744,  0.00251256],\n",
       "       [ 0.22911051,  0.77088949],\n",
       "       [ 0.99230769,  0.00769231],\n",
       "       [ 0.11282051,  0.88717949],\n",
       "       [ 0.94444444,  0.05555556],\n",
       "       [ 0.04712042,  0.95287958],\n",
       "       [ 0.99244332,  0.00755668],\n",
       "       [ 0.99465241,  0.00534759],\n",
       "       [ 0.99234694,  0.00765306],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.93582888,  0.06417112],\n",
       "       [ 0.01846966,  0.98153034],\n",
       "       [ 0.06332454,  0.93667546],\n",
       "       [ 0.04511278,  0.95488722],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.99208443,  0.00791557],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.93175853,  0.06824147],\n",
       "       [ 0.07795699,  0.92204301],\n",
       "       [ 0.98910082,  0.01089918],\n",
       "       [ 0.21409922,  0.78590078],\n",
       "       [ 0.00526316,  0.99473684],\n",
       "       [ 0.05026455,  0.94973545],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.81889764,  0.18110236],\n",
       "       [ 0.08201058,  0.91798942],\n",
       "       [ 0.12820513,  0.87179487],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.96816976,  0.03183024],\n",
       "       [ 0.21052632,  0.78947368],\n",
       "       [ 0.92913386,  0.07086614],\n",
       "       [ 0.05958549,  0.94041451],\n",
       "       [ 0.09375   ,  0.90625   ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.93094629,  0.06905371],\n",
       "       [ 0.5646438 ,  0.4353562 ],\n",
       "       [ 0.83550914,  0.16449086],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.04060914,  0.95939086],\n",
       "       [ 0.95392954,  0.04607046],\n",
       "       [ 0.03743316,  0.96256684],\n",
       "       [ 0.12207792,  0.87792208],\n",
       "       [ 0.93622449,  0.06377551],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.0987013 ,  0.9012987 ],\n",
       "       [ 0.70052083,  0.29947917]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Patches and Random Subspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92000000000000004"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra-Trees\n",
    "### Features Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.0927775993862\n",
      "sepal width (cm) 0.0222623951091\n",
      "petal length (cm) 0.42929411052\n",
      "petal width (cm) 0.455665894985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Boosting\n",
    "\n",
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.5, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5\n",
    "    )\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=1.0, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=3, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=49, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
    "\n",
    "best_n_estimators = np.argmin(errors)\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=best_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_uo=0\n",
    "for n_estimators in range(1,120):\n",
    "    gbrt.n_estimators=n_estimators\n",
    "    gbrt.fit(X_train,y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error=val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up = error_going_up+1\n",
    "        if error_going_up == 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
